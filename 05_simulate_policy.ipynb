{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we simulate different policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/DeenoZord/Documents/All_Files_Laptop/Coding/Pyton_Files/Functions_and_modules')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# import usefulFunctions as uf\n",
    "# importlib.reload(uf)\n",
    "\n",
    "from wgm2018_pack import *\n",
    "\n",
    "import winsound \n",
    "import scipy.stats as stt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonr_(x,y):\n",
    "    [r,p] = stt.pearsonr(x,y)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_avg_corr(list_of_aggregated_nodes, list_of_aggregated_nodes_n, metrics, exclude_same_question=True, print_=False,  df=wgm_bool):\n",
    "    # The first aggregated node is the one that you'll use to calculate the correlation\n",
    "    \n",
    "#     print(list_of_aggregated_nodes_n)\n",
    "    a_node_i_name = list_of_aggregated_nodes_n[0]\n",
    "    a_node_i = list_of_aggregated_nodes[0]\n",
    "    \n",
    "    count = 0\n",
    "    for j, a_node_j_name in enumerate(list_of_aggregated_nodes_n):\n",
    "        if j == 0:\n",
    "            pass\n",
    "        else:            \n",
    "            a_node_j = list_of_aggregated_nodes[j]\n",
    "\n",
    "    #         count = 0\n",
    "            avg_weight = 0\n",
    "    #             print(a_node_i)\n",
    "            for ii, node_i in enumerate(a_node_i):\n",
    "                for jj, node_j in enumerate(a_node_j):\n",
    "\n",
    "    #                         if print_:\n",
    "    #                             n_tot = len(list_of_nodes)**2\n",
    "    #                             current = (i*len(list_of_nodes))+(j)\n",
    "    #                             print(current,\"/\",n_tot, \" = \", np.round(current/n_tot,decimals=2))\n",
    "\n",
    "                    if exclude_same_question:\n",
    "                        if node_i.split(sep=':')[0] == node_j.split(sep=':')[0]:\n",
    "                            # if they belong to the same question\n",
    "                            continue\n",
    "\n",
    "                    [c1,c2] = get_col_values([node_i,node_j],df=df)\n",
    "                    weight = metrics(c1,c2)\n",
    "\n",
    "                    if not np.isnan(weight):\n",
    "                        avg_weight = (weight + avg_weight*count)/(count+1)\n",
    "                        count += 1\n",
    "\n",
    "    return avg_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def booleanize(df, list_of_questions):\n",
    "    df_bool = pd.DataFrame()\n",
    "    list_of_attitudes = []\n",
    "\n",
    "    for quest in list_of_questions:\n",
    "    #     values = sorted(df[quest].unique()) # list of unique values of the dataset\n",
    "        values = (df[quest].unique()) # list of unique values of the dataset\n",
    "    #     min_ = min_dic[quest]\n",
    "    #     max_ = max_dic[quest]\n",
    "\n",
    "        for value in values:\n",
    "            if type(value) == type('dsf'):\n",
    "                name = str(quest)+\":\"+str(value) \n",
    "                df_bool[name] = df[quest] == value\n",
    "                list_of_attitudes.append(name)           \n",
    "            else:\n",
    "                if np.isnan(value): # if it's a refused answer\n",
    "                    name = str(quest)+\":\"+\"Ref\" \n",
    "                    try:\n",
    "                        df_bool[name] = df_bool[name] | df[quest] == value\n",
    "                    except:\n",
    "                        list_of_attitudes.append(name)\n",
    "                        df_bool[name] = df[quest] == value\n",
    "                else:\n",
    "                    name = str(quest)+\":\"+str(value) \n",
    "                    df_bool[name] = df[quest] == value\n",
    "                    list_of_attitudes.append(name)\n",
    "    return df_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_aggr_vacc2 = ['vacc_neut_att',\n",
    " 'vacc_Wpos_att',\n",
    " 'vacc_Wneg_att',\n",
    " 'vacc_Sneg_att']\n",
    "\n",
    "list_aggr_vacc_Spos = ['vacc_Spos_att']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_neut_att = ['Vaccines important to children:Neither agree nor disagree', 'Vaccines Safe:Neither agree nor disagree', 'Vaccines Effective:Neither agree nor disagree']\n",
    "\n",
    "vacc_pos_att = ['Vaccines important to children:Strongly agree',\n",
    " 'Vaccines important to children:Somewhat agree','Vaccines Safe:Strongly agree',\n",
    " 'Vaccines Safe:Somewhat agree','Vaccines Effective:Strongly agree',\n",
    " 'Vaccines Effective:Somewhat agree']\n",
    "vacc_Wpos_att = ['Vaccines important to children:Somewhat agree',\n",
    "                 'Vaccines Safe:Somewhat agree', 'Vaccines Effective:Somewhat agree']\n",
    "vacc_Spos_att = ['Vaccines important to children:Strongly agree',\n",
    "                 'Vaccines Safe:Strongly agree', 'Vaccines Effective:Strongly agree']\n",
    "    \n",
    "vacc_neg_att = ['Vaccines important to children:Somewhat disagree',\n",
    " 'Vaccines important to children:Strongly disagree','Vaccines Safe:Somewhat disagree',\n",
    " 'Vaccines Safe:Strongly disagree','Vaccines Effective:Somewhat disagree',\n",
    " 'Vaccines Effective:Strongly disagree']\n",
    "vacc_Wneg_att = ['Vaccines important to children:Somewhat disagree',\n",
    "                 'Vaccines Safe:Somewhat disagree','Vaccines Effective:Somewhat disagree']\n",
    "vacc_Sneg_att = ['Vaccines important to children:Strongly disagree',\n",
    "                 'Vaccines Safe:Strongly disagree','Vaccines Effective:Strongly disagree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_neut_att2 = ['Vaccines important to children:3', 'Vaccines Safe:3', \n",
    "                  'Vaccines Effective:3']\n",
    "vacc_Wpos_att2 = ['Vaccines important to children:2',\n",
    "                 'Vaccines Safe:2', 'Vaccines Effective:2']\n",
    "vacc_Spos_att2 = ['Vaccines important to children:1',\n",
    "                 'Vaccines Safe:1', 'Vaccines Effective:1']    \n",
    "vacc_Wneg_att2 = ['Vaccines important to children:4',\n",
    "                 'Vaccines Safe:4','Vaccines Effective:4']\n",
    "vacc_Sneg_att2 = ['Vaccines important to children:5',\n",
    "                 'Vaccines Safe:5','Vaccines Effective:5']\n",
    "\n",
    "list_of_aggregated_nodes_n = ['vacc_Spos_att2', 'vacc_neut_att2', 'vacc_Wpos_att2']\n",
    "\n",
    "list_questions = [\"Vaccines important to children\", \"Vaccines Safe\",\"Vaccines Effective\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the initial isolation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation without any intervention:  0.09322222093761008\n"
     ]
    }
   ],
   "source": [
    "df2_numeric = wgm_numeric.copy()\n",
    "df2_numeric = df2_numeric[['Vaccines Safe', 'Vaccines Effective', 'Vaccines important to children']]\n",
    "df=booleanize(df2_numeric, list_questions)\n",
    "\n",
    "# Extra parameters\n",
    "exclude_same_question = True # True or false\n",
    "\n",
    "metrics = pearsonr_\n",
    "\n",
    "# Turn the names into attitudes\n",
    "list_of_aggregated_nodes = []\n",
    "for name in list_of_aggregated_nodes_n:\n",
    "#     print(\"t = \"+name)\n",
    "    exec(\"t = \"+name)\n",
    "    list_of_aggregated_nodes.append(t)\n",
    "\n",
    "# Get the isolation measur\n",
    "avg_corr = check_avg_corr(list_of_aggregated_nodes, list_of_aggregated_nodes_n, metrics, exclude_same_question=exclude_same_question, print_=False,  df=df)\n",
    "\n",
    "base = avg_corr\n",
    "\n",
    "print(\"Isolation without any intervention: \", -avg_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation value after this intervention:  0.12210280440625056\n",
      "Improvement due to intervention =  -0.3098036410006697\n",
      "People selected: 0.04990714285714286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_num = df2_numeric.copy()\n",
    "koeff = 0.55 # the higher this value, the more people we'll randomly select for the policy\n",
    "\n",
    "count = 0\n",
    "for col in df_num.columns: # for each column (i.e. for each attitude)\n",
    "    line_current = df_num[col]\n",
    "    line_1 = df_num[df_num.columns[0]]\n",
    "    line_2 = df_num[df_num.columns[1]]\n",
    "    line_3 = df_num[df_num.columns[2]]\n",
    "    \n",
    "    for i,el in enumerate(line_current): # for each person\n",
    "        el1 = line_1[i]\n",
    "        el2 = line_2[i]\n",
    "        el3 = line_3[i]\n",
    "        \n",
    "        n_valid = np.sum([type(x)==int for x in [el1, el2, el3]]) # number of valid answers\n",
    "        \n",
    "        if (n_valid == 3) and (el==2): # if all answers \n",
    "            \n",
    "            n_interesting1 = np.sum([x==1 for x in [el1, el2, el3]]) # \n",
    "            \n",
    "            if n_interesting1==2: # if it's already 5 it doesn't make sense\n",
    "                if np.random.rand()<koeff:\n",
    "                    count += 1\n",
    "                    df_num[col][i]=1\n",
    "\n",
    "# Booleanize\n",
    "df3_bool = booleanize(df_num, list_questions)\n",
    "\n",
    "# Calculate the distance\n",
    "\n",
    "df = df3_bool\n",
    "\n",
    "# Extra parameters\n",
    "exclude_same_question = True # True or false\n",
    "\n",
    "metrics = pearsonr_\n",
    "\n",
    "# Turn the names into attitudes\n",
    "list_of_aggregated_nodes = []\n",
    "for name in list_of_aggregated_nodes_n:\n",
    "#     print(\"t = \"+name)\n",
    "    exec(\"t = \"+name)\n",
    "    list_of_aggregated_nodes.append(t)\n",
    "\n",
    "# Get the isolation measur\n",
    "avg_corr = check_avg_corr(list_of_aggregated_nodes, list_of_aggregated_nodes_n, metrics, exclude_same_question=exclude_same_question, print_=False,  df=df)\n",
    "\n",
    "print(\"Isolation value after this intervention: \", -avg_corr)\n",
    "print(\"Improvement due to intervention = \", (1-avg_corr/base))\n",
    "print(\"People selected:\",count/140000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervention tailored at decreasing isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation value after this intervention:  0.0444553188545165\n",
      "Improvement due to intervention =  0.5231252977305842\n",
      "People selected: 0.05076428571428571\n"
     ]
    }
   ],
   "source": [
    "## Make policy\n",
    "df_num = df2_numeric.copy()\n",
    "koeff = 0.299 # the higher this value, the more people we'll randomly select for the policy\n",
    "\n",
    "count = 0\n",
    "for col in df_num.columns: # for each column (i.e. for each attitude)\n",
    "    line_current = df_num[col]\n",
    "    line_1 = df_num[df_num.columns[0]]\n",
    "    line_2 = df_num[df_num.columns[1]]\n",
    "    line_3 = df_num[df_num.columns[2]]\n",
    "    \n",
    "    for i,el in enumerate(line_current): # for each person\n",
    "        el1 = line_1[i]\n",
    "        el2 = line_2[i]\n",
    "        el3 = line_3[i]\n",
    "        \n",
    "        n_valid = np.sum([type(x)==int for x in [el1, el2, el3]]) # number of valid answers\n",
    "        \n",
    "        if (n_valid == 3) and (el<=2) and (el>1): # if all answers \n",
    "            \n",
    "            n_interesting1 = np.sum([x>1 for x in [el1, el2, el3]]) # \n",
    "            \n",
    "            if n_interesting1==3: \n",
    "                if np.random.rand()<koeff:\n",
    "                    count += 1\n",
    "                    df_num[col][i]=df_num[col][i]-1\n",
    "                        \n",
    "# Booleanize\n",
    "df3_bool = booleanize(df_num, list_questions)\n",
    "\n",
    "df = df3_bool\n",
    "\n",
    "# Extra parameters\n",
    "exclude_same_question = True # True or false\n",
    "\n",
    "metrics = pearsonr_\n",
    "\n",
    "# Turn the names into attitudes\n",
    "list_of_aggregated_nodes = []\n",
    "for name in list_of_aggregated_nodes_n:\n",
    "#     print(\"t = \"+name)\n",
    "    exec(\"t = \"+name)\n",
    "    list_of_aggregated_nodes.append(t)\n",
    "\n",
    "# Get the isolation measur\n",
    "avg_corr = check_avg_corr(list_of_aggregated_nodes, list_of_aggregated_nodes_n, metrics, exclude_same_question=exclude_same_question, print_=False,  df=df)\n",
    "\n",
    "print(\"Isolation value after this intervention: \", -avg_corr)\n",
    "print(\"Improvement due to intervention = \", (1-avg_corr/base))\n",
    "print(\"People selected:\",count/140000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
